led_yellow: GPIO 17번 핀 (happy)
led_red: GPIO 4번 핀 (expressionless)
led_green: GPIO 27번 핀 (surprised)


import tensorflow.keras
import numpy as np
import cv2
import pygame
import time
from gpiozero import LED

# TensorFlow 모델 로드
model = tensorflow.keras.models.load_model('/home/pi/cos/converted_keras/converted_keras/keras_model.h5')

# OpenCV로 웹캠 캡처 시작
cap = cv2.VideoCapture(0)
size = (224, 224)
classes = ['happy', 'expressionless', 'surprised']

# Pygame 초기화 및 음악 파일 로드
pygame.mixer.init()
music_files = {
    'happy': '/home/pi/cos/converted_keras/happy.mp3',
    'expressionless': '/home/pi/cos/converted_keras/expressionless.mp3',
    'surprised': '/home/pi/cos/converted_keras/surprised.mp3'
}

# 이미지 파일 경로 (음악 재생 중에 표시할 이미지)
images_to_show = {
    'happy': '/home/pi/cos/converted_keras/happy_image.jpg',
    'expressionless': '/home/pi/cos/converted_keras/expressionless_image.jpg',
    'surprised': '/home/pi/cos/converted_keras/surprised_image.jpg'
}

# LED 설정 (GPIO 핀 번호)
led_yellow = LED(17)  # happy
led_red = LED(4)      # expressionless
led_green = LED(27)   # surprised

def play_music(emotion):
    # 감정에 맞는 LED 켜기
    if emotion == 'happy':
        led_yellow.on()
        led_red.off()
        led_green.off()
    elif emotion == 'expressionless':
        led_yellow.off()
        led_red.on()
        led_green.off()
    elif emotion == 'surprised':
        led_yellow.off()
        led_red.off()
        led_green.on()

    # 음악 재생
    pygame.mixer.music.load(music_files[emotion])
    pygame.mixer.music.play()

    # 음악 재생 중 이미지 및 시간 표시
    img = cv2.imread(images_to_show[emotion])
    
    while pygame.mixer.music.get_busy():
        # 현재 재생된 시간 계산
        elapsed_time = int(pygame.mixer.music.get_pos() / 1000)  # 밀리초를 초로 변환
        
        # 이미지에 재생 시간 추가
        display_img = img.copy()
        cv2.putText(display_img, f"Time: {elapsed_time}s", (10, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)
        
        # 이미지 화면에 표시
        cv2.imshow('Emotion Image', display_img)
        key = cv2.waitKey(100) & 0xFF
        
        if key == ord('v'):  # 'v'를 누르면 음악과 이미지 중지 및 카메라 캡처
            pygame.mixer.music.stop()
            capture_frame()
            break

    cv2.destroyWindow('Emotion Image')

    # 모든 LED 끄기
    led_yellow.off()
    led_red.off()
    led_green.off()

def capture_frame():
    # 현재 카메라 프레임 캡처 및 저장
    ret, frame = cap.read()
    if ret:
        # 캡처된 이미지 저장
        timestamp = time.strftime("%Y%m%d-%H%M%S")
        filename = f"/home/pi/cos/converted_keras/captured_{timestamp}.jpg"
        cv2.imwrite(filename, frame)
        print(f"이미지 저장 완료: {filename}")

# 웹캠에서 이미지 인식 및 음악 재생 루프
while cap.isOpened():
    ret, img = cap.read()
    if not ret:
        break

    h, w, _ = img.shape
    cx = h / 2
    img = img[:, 100:100 + img.shape[0]]
    img = cv2.flip(img, 1)

    # 이미지 전처리
    img_input = cv2.resize(img, size)
    img_input = cv2.cvtColor(img_input, cv2.COLOR_BGR2RGB)
    img_input = (img_input.astype(np.float32) / 127.0) - 1
    img_input = np.expand_dims(img_input, axis=0)

    # 모델 예측
    prediction = model.predict(img_input)
    idx = np.argmax(prediction)
    detected_emotion = classes[idx]

    # 결과 표시
    smaller_img = cv2.resize(img, (800, 600))
    cv2.putText(smaller_img, text=detected_emotion, org=(10, 30), fontFace=cv2.FONT_HERSHEY_SIMPLEX,
                fontScale=0.8, color=(255, 255, 255), thickness=2)
    cv2.imshow('result', smaller_img)

    # 인식된 표정에 따라 음악 재생 및 LED 제어
    play_music(detected_emotion)

    # 'q' 키를 누르면 종료
    if cv2.waitKey(1) == ord('q'):
        break

cap.release()
cv2.destroyAllWindows()


1) capture_frame 함수 추가:

v를 눌렀을 때 호출되며, 현재 카메라에서 프레임을 캡처하여 파일로 저장합니다.
파일 이름에는 타임스탬프가 포함되어 저장될 때마다 다른 이름을 갖게 됩니다.

2) play_music 함수의 v 키 동작 변경:

v 키를 누르면 pygame.mixer.music.stop()을 호출해 음악을 중지하고, 
capture_frame()을 호출하여 현재 카메라 프레임을 캡처하고 저장합니다.
이제 v 키를 누르면 음악과 이미지가 중지되고, 
그 시점의 카메라 이미지를 캡처하여 저장하게 됩니다. 
원하는 위치에 이미지를 저장하고 파일명을 쉽게 구분할 수 있도록 타임스탬프 형식으로 지정했습니다.
