happy: 17번 (yellow)
expressionless: 4번 (red)
surprised: 27번 (green)


import tensorflow.keras
import numpy as np
import cv2
import pygame
import time
from gpiozero import LED

# TensorFlow 모델 로드
model = tensorflow.keras.models.load_model('/home/pi/cos/converted_keras/converted_keras/keras_model.h5')

# OpenCV로 웹캠 캡처 시작
cap = cv2.VideoCapture(0)
size = (224, 224)
classes = ['happy', 'expressionless', 'surprised']

# Pygame 초기화 및 음악 파일 로드
pygame.mixer.init()
music_files = {
    'happy': '/home/pi/cos/converted_keras/happy.mp3',
    'expressionless': '/home/pi/cos/converted_keras/expressionless.mp3',
    'surprised': '/home/pi/cos/converted_keras/surprised.mp3'
}

# LED 설정 (GPIO 핀 번호)
led_yellow = LED(17)  # happy
led_red = LED(4)      # expressionless
led_green = LED(27)   # surprised

def play_music(emotion):
    # 각 감정에 맞는 LED 켜기
    if emotion == 'happy':
        led_yellow.on()
        led_red.off()
        led_green.off()
    elif emotion == 'expressionless':
        led_yellow.off()
        led_red.on()
        led_green.off()
    elif emotion == 'surprised':
        led_yellow.off()
        led_red.off()
        led_green.on()

    # 음악 재생
    pygame.mixer.music.load(music_files[emotion])
    pygame.mixer.music.play()
    time.sleep(60)  # 1분 재생
    pygame.mixer.music.stop()

    # 모든 LED 끄기
    led_yellow.off()
    led_red.off()
    led_green.off()

# 웹캠에서 이미지 인식 및 음악 재생 루프
while cap.isOpened():
    ret, img = cap.read()
    if not ret:
        break

    h, w, _ = img.shape
    cx = h / 2
    img = img[:, 100:100 + img.shape[0]]
    img = cv2.flip(img, 1)

    # 이미지 전처리
    img_input = cv2.resize(img, size)
    img_input = cv2.cvtColor(img_input, cv2.COLOR_BGR2RGB)
    img_input = (img_input.astype(np.float32) / 127.0) - 1
    img_input = np.expand_dims(img_input, axis=0)

    # 모델 예측
    prediction = model.predict(img_input)
    idx = np.argmax(prediction)
    detected_emotion = classes[idx]

    # 결과 표시
    smaller_img = cv2.resize(img, (800, 600))
    cv2.putText(smaller_img, text=detected_emotion, org=(10, 30), fontFace=cv2.FONT_HERSHEY_SIMPLEX,
                fontScale=0.8, color=(255, 255, 255), thickness=2)
    cv2.imshow('result', smaller_img)

    # 인식된 표정에 따라 음악 재생 및 LED 제어
    play_music(detected_emotion)

    # 'q' 키를 누르면 종료
    if cv2.waitKey(1) == ord('q'):
        break

cap.release()
cv2.destroyAllWindows()

