1ë‹¨ê³„: ì¹´ë©”ë¼ì—ì„œ ëˆˆë™ìë¥¼ ì¸ì‹í•˜ëŠ” ì½”ë“œ ì‘ì„±
 1.í”„ë¡œì íŠ¸ ì„¤ì •
ë¨¼ì € í”„ë¡œì íŠ¸ë¥¼ ìœ„í•œ ê°€ìƒí™˜ê²½ì„ ë§Œë“¤ê³  í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì„¤ì¹˜í•˜ê² ìŠµë‹ˆë‹¤.
ğŸ”¹ ê°€ìƒí™˜ê²½ ìƒì„± ë° í™œì„±í™”

  conda create -n eye_tracking python=3.9 -y
  conda activate eye_tracking
  
  eye_trackingì´ë¼ëŠ” ê°€ìƒí™˜ê²½ì„ ë§Œë“¤ê³  Python 3.9ì„ ì„¤ì¹˜í•©ë‹ˆë‹¤.
  í™˜ê²½ì„ í™œì„±í™”í•©ë‹ˆë‹¤.

ğŸ”¹ í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜
ì¹´ë©”ë¼ë¥¼ ì‚¬ìš©í•˜ê³  ì–¼êµ´ì„ ê°ì§€í•˜ê¸° ìœ„í•´ í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì„¤ì¹˜í•©ë‹ˆë‹¤.

pip install opencv-python dlib numpy

âœ… ì„¤ì¹˜ëœ íŒ¨í‚¤ì§€
opencv-python â†’ ì›¹ìº  ì‚¬ìš© ë° ì´ë¯¸ì§€ ì²˜ë¦¬
dlib â†’ ì–¼êµ´ ëœë“œë§ˆí¬ ê°ì§€ë¥¼ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬
numpy â†’ ë°ì´í„° ì²˜ë¦¬


âœ… 2. ëˆˆë™ì ì¸ì‹ ì½”ë“œ ì‘ì„±
ì´ì œ ì¹´ë©”ë¼ì—ì„œ ì–¼êµ´ì„ ê°ì§€í•˜ê³ , ëˆˆë™ìë¥¼ ì¶”ì í•˜ëŠ” ì½”ë“œë¥¼ ì‘ì„±í•˜ê² ìŠµë‹ˆë‹¤.

ğŸ”¹ eye_tracking.py ì½”ë“œ
import cv2
import dlib

# Dlib ì–¼êµ´ ê°ì§€ê¸° ë° ëœë“œë§ˆí¬ ëª¨ë¸ ë¡œë“œ
detector = dlib.get_frontal_face_detector()
predictor = dlib.shape_predictor("shape_predictor_68_face_landmarks.dat")  # ëª¨ë¸ íŒŒì¼ í•„ìš”

# ì›¹ìº  ì—´ê¸°
cap = cv2.VideoCapture(0)

def get_eye_centers(landmarks):
    """ëˆˆë™ì ì¤‘ì‹¬ ì¢Œí‘œ ê³„ì‚°"""
    left_eye = landmarks.parts()[36:42]  # ì™¼ìª½ ëˆˆ
    right_eye = landmarks.parts()[42:48]  # ì˜¤ë¥¸ìª½ ëˆˆ

    left_center = (sum([p.x for p in left_eye]) // 6, sum([p.y for p in left_eye]) // 6)
    right_center = (sum([p.x for p in right_eye]) // 6, sum([p.y for p in right_eye]) // 6)

    return left_center, right_center

while True:
    ret, frame = cap.read()
    if not ret:
        break

    # ì¢Œìš° ë°˜ì „
    frame = cv2.flip(frame, 1)

    # í‘ë°± ë³€í™˜
    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)

    # ì–¼êµ´ ê°ì§€
    faces = detector(gray)
    for face in faces:
        landmarks = predictor(gray, face)

        # ëˆˆë™ì ì¤‘ì‹¬ ì¢Œí‘œ ê°€ì ¸ì˜¤ê¸°
        left_eye_center, right_eye_center = get_eye_centers(landmarks)

        # ëˆˆë™ì ìœ„ì¹˜ í‘œì‹œ
        cv2.circle(frame, left_eye_center, 5, (0, 255, 0), -1)  # ì´ˆë¡ìƒ‰ ì 
        cv2.circle(frame, right_eye_center, 5, (0, 255, 0), -1)

    # í™”ë©´ ì¶œë ¥
    cv2.imshow("Eye Tracking", frame)

    # 'q'ë¥¼ ëˆ„ë¥´ë©´ ì¢…ë£Œ
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

cap.release()
cv2.destroyAllWindows()



âœ… 3. ì‹¤í–‰ ë°©ë²•
shape_predictor_68_face_landmarks.dat íŒŒì¼ì´ í”„ë¡œì íŠ¸ í´ë”ì— ìˆì–´ì•¼ í•©ë‹ˆë‹¤.

ë‹¤ìš´ë¡œë“œ ë§í¬: Dlib Face Landmark Model
ì••ì¶•ì„ í’€ê³  í”„ë¡œì íŠ¸ í´ë”ì— ì €ì¥í•˜ì„¸ìš”.

Python ì‹¤í–‰
python eye_tracking.py

ì›¹ìº ì´ ì‹¤í–‰ë˜ë©´ ì–¼êµ´ì„ ê°ì§€í•˜ê³ , ëˆˆë™ì ìœ„ì¹˜ì— ì´ˆë¡ìƒ‰ ì ì´ í‘œì‹œë©ë‹ˆë‹¤.

